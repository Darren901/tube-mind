# èªéŸ³æ’­å ±åŠŸèƒ½å¯¦ä½œè¨ˆç•«

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**ç›®æ¨™**: åœ¨æ‘˜è¦è©³ç´°é é¢æ–°å¢èªéŸ³æ’­æ”¾å™¨ï¼Œä½¿ç”¨è€…å¯ä»¥æ’­æ”¾ AI èªéŸ³æœ—è®€æ‘˜è¦å…§å®¹ã€‚

**æ¶æ§‹**: å‰ç«¯ä½¿ç”¨ HTML5 audio + React è‡ªè¨‚ UI æ§åˆ¶æ’­æ”¾å™¨ï¼Œå¾Œç«¯æä¾› API ç«¯é»å‘¼å« Google Cloud TTS ç”ŸæˆèªéŸ³ä¸¦ä¸Šå‚³åˆ° GCSï¼Œé¦–æ¬¡ç”Ÿæˆå¾Œå¿«å– URL åˆ°è³‡æ–™åº«ã€‚

**æŠ€è¡“æ£§**: 
- Google Cloud Text-to-Speech API (ç¹é«”ä¸­æ–‡èªéŸ³)
- Google Cloud Storage (éŸ³è¨Šæª”æ¡ˆå„²å­˜)
- React + TypeScript (æ’­æ”¾å™¨ UI)
- Prisma (è³‡æ–™åº« ORM)
- Lucide React (åœ–ç¤º)

---

## Phase 1: åŸºç¤è¨­å®šèˆ‡è³‡æ–™åº«

### Task 1: æ›´æ–° Prisma Schema

**Files:**
- Modify: `prisma/schema.prisma` (åœ¨ Summary model ä¸­æ–°å¢æ¬„ä½)

**Step 1: æ–°å¢éŸ³è¨Šæ¬„ä½åˆ° Summary model**

åœ¨ `prisma/schema.prisma` çš„ `model Summary` ä¸­ï¼Œæ–¼æœ€å¾Œä¸€å€‹æ¬„ä½å¾Œæ–°å¢ï¼š

```prisma
  audioUrl         String?   // GCS ä¸Šçš„èªéŸ³æª”å…¬é–‹ URL
  audioGeneratedAt DateTime? // èªéŸ³ç”Ÿæˆæ™‚é–“ï¼ˆç”¨æ–¼å¿«å–ç®¡ç†ï¼‰
```

å®Œæ•´ä½ç½®æ‡‰è©²åœ¨ `summaryTags SummaryTag[]` ä¹‹å¾Œï¼Œ`@@unique` ä¹‹å‰ã€‚

**Step 2: åŸ·è¡Œè³‡æ–™åº«é·ç§»**

```bash
npx prisma migrate dev --name add_audio_to_summary
```

é æœŸè¼¸å‡ºï¼šMigration æˆåŠŸå»ºç«‹ï¼Œè³‡æ–™åº«å·²æ›´æ–°

**Step 3: æª¢æŸ¥ç”Ÿæˆçš„ Prisma Client**

```bash
npx prisma generate
```

é æœŸè¼¸å‡ºï¼šPrisma Client å·²é‡æ–°ç”Ÿæˆ

**Step 4: Commit**

```bash
git add prisma/schema.prisma prisma/migrations/
git commit -m "feat(db): add audio fields to Summary model"
```

---

### Task 2: å®‰è£ Google Cloud ç›¸é—œå¥—ä»¶

**Files:**
- Modify: `package.json`

**Step 1: å®‰è£ Google Cloud å¥—ä»¶**

```bash
npm install @google-cloud/text-to-speech @google-cloud/storage
```

**Step 2: å®‰è£å‹åˆ¥å®šç¾©**

```bash
npm install -D @types/google-cloud__text-to-speech @types/google-cloud__storage
```

**Step 3: Commit**

```bash
git add package.json package-lock.json
git commit -m "feat(deps): add Google Cloud TTS and Storage SDKs"
```

---

### Task 3: è¨­å®šç’°å¢ƒè®Šæ•¸

**Files:**
- Modify: `.env.local` (æœ¬åœ°é–‹ç™¼ï¼Œä¸ commit)
- Create: `.env.example` (ç¯„ä¾‹æª”æ¡ˆï¼Œå¯ commit)

**Step 1: æ–°å¢ç’°å¢ƒè®Šæ•¸åˆ° .env.local**

```env
# Google Cloud æœå‹™å¸³è™Ÿé‡‘é‘°è·¯å¾‘
GOOGLE_APPLICATION_CREDENTIALS=./service-account-key.json

# GCS Bucket åç¨±
GCS_BUCKET_NAME=tube-mind-audio-dev
```

**Step 2: å»ºç«‹ .env.example**

```env
# Google Cloud Text-to-Speech & Storage
GOOGLE_APPLICATION_CREDENTIALS=./service-account-key.json
GCS_BUCKET_NAME=tube-mind-audio-dev
```

**Step 3: Commit .env.example**

```bash
git add .env.example
git commit -m "docs: add environment variables for audio feature"
```

**Note**: åœ¨åŸ·è¡Œå¾ŒçºŒä»»å‹™å‰ï¼Œéœ€è¦æ‰‹å‹•è¨­å®š Google Cloudï¼š
1. å•Ÿç”¨ Cloud Text-to-Speech API å’Œ Cloud Storage API
2. å»ºç«‹ GCS Bucket
3. ä¸‹è¼‰æœå‹™å¸³è™Ÿé‡‘é‘°åˆ°å°ˆæ¡ˆæ ¹ç›®éŒ„

---

## Phase 2: å¾Œç«¯ API å¯¦ä½œ

### Task 4: å»ºç«‹ TTS å’Œ GCS å·¥å…·å‡½å¼

**Files:**
- Create: `lib/audio/tts.ts`
- Create: `lib/audio/storage.ts`

**Step 1: å»ºç«‹ TTS å·¥å…·å‡½å¼**

Create `lib/audio/tts.ts`:

```typescript
import { TextToSpeechClient } from '@google-cloud/text-to-speech'

const client = new TextToSpeechClient()

export interface TTSOptions {
  text: string
  languageCode?: string
  voiceName?: string
}

export async function generateSpeech(options: TTSOptions): Promise<Buffer> {
  const { text, languageCode = 'zh-TW', voiceName = 'zh-TW-Standard-A' } = options

  const [response] = await client.synthesizeSpeech({
    input: { text },
    voice: {
      languageCode,
      name: voiceName,
      ssmlGender: 'FEMALE',
    },
    audioConfig: {
      audioEncoding: 'MP3',
      speakingRate: 1.0,
      pitch: 0.0,
      volumeGainDb: 0.0,
    },
  })

  if (!response.audioContent) {
    throw new Error('TTS ç”Ÿæˆå¤±æ•—ï¼šç„¡éŸ³è¨Šå…§å®¹')
  }

  return Buffer.from(response.audioContent as Uint8Array)
}
```

**Step 2: å»ºç«‹ GCS ä¸Šå‚³å·¥å…·å‡½å¼**

Create `lib/audio/storage.ts`:

```typescript
import { Storage } from '@google-cloud/storage'

const storage = new Storage()
const bucketName = process.env.GCS_BUCKET_NAME!

if (!bucketName) {
  throw new Error('GCS_BUCKET_NAME ç’°å¢ƒè®Šæ•¸æœªè¨­å®š')
}

const bucket = storage.bucket(bucketName)

export async function uploadAudio(
  buffer: Buffer,
  filename: string
): Promise<string> {
  const file = bucket.file(filename)

  await file.save(buffer, {
    metadata: {
      contentType: 'audio/mpeg',
      cacheControl: 'public, max-age=31536000', // å¿«å–ä¸€å¹´
    },
  })

  // è¨­å®šå…¬é–‹è®€å–æ¬Šé™
  await file.makePublic()

  // å›å‚³å…¬é–‹ URL
  return `https://storage.googleapis.com/${bucketName}/${filename}`
}
```

**Step 3: Commit**

```bash
git add lib/audio/
git commit -m "feat(audio): add TTS and GCS utility functions"
```

---

### Task 5: å»ºç«‹éŸ³è¨Š API ç«¯é»

**Files:**
- Create: `app/api/summaries/[id]/audio/route.ts`

**Step 1: å»ºç«‹ API è·¯ç”±æª”æ¡ˆ**

Create `app/api/summaries/[id]/audio/route.ts`:

```typescript
import { NextResponse } from 'next/server'
import { getServerSession } from 'next-auth'
import { authOptions } from '@/lib/auth'
import { prisma } from '@/lib/db'
import { generateSpeech } from '@/lib/audio/tts'
import { uploadAudio } from '@/lib/audio/storage'

interface SummaryContent {
  topic: string
  keyPoints: string[]
  sections: {
    timestamp: string
    title: string
    summary: string
  }[]
}

export const maxDuration = 30 // Vercel timeout: 30 ç§’

export async function POST(
  request: Request,
  { params }: { params: { id: string } }
) {
  try {
    // 1. é©—è­‰ä½¿ç”¨è€…
    const session = await getServerSession(authOptions)
    if (!session?.user) {
      return NextResponse.json({ error: 'è«‹å…ˆç™»å…¥' }, { status: 401 })
    }

    // 2. æŸ¥è©¢æ‘˜è¦
    const summary = await prisma.summary.findFirst({
      where: {
        id: params.id,
        userId: session.user.id,
      },
      include: {
        video: true,
      },
    })

    if (!summary) {
      return NextResponse.json({ error: 'æ‰¾ä¸åˆ°è©²æ‘˜è¦' }, { status: 404 })
    }

    if (summary.status !== 'completed') {
      return NextResponse.json(
        { error: 'æ‘˜è¦å°šæœªå®Œæˆï¼Œç„¡æ³•ç”ŸæˆèªéŸ³' },
        { status: 400 }
      )
    }

    // 3. æª¢æŸ¥å¿«å–
    if (summary.audioUrl) {
      return NextResponse.json({
        audioUrl: summary.audioUrl,
      })
    }

    // 4. çµ„åˆæ–‡å­—å…§å®¹
    const content = summary.content as unknown as SummaryContent
    const textParts: string[] = []

    textParts.push(`ä¸»é¡Œï¼š${content.topic}`)
    textParts.push(`æ ¸å¿ƒè§€é»ï¼š${content.keyPoints.join('ã€')}`)

    content.sections.forEach((section) => {
      textParts.push(`${section.title}ã€‚${section.summary}`)
    })

    const combinedText = textParts.join('\n\n')

    // 5. ç”ŸæˆèªéŸ³
    console.log(`[Audio] é–‹å§‹ç”ŸæˆèªéŸ³ï¼Œæ‘˜è¦ ID: ${params.id}`)
    const audioBuffer = await generateSpeech({ text: combinedText })

    // 6. ä¸Šå‚³åˆ° GCS
    const filename = `audio/${params.id}.mp3`
    console.log(`[Audio] ä¸Šå‚³åˆ° GCS: ${filename}`)
    const audioUrl = await uploadAudio(audioBuffer, filename)

    // 7. æ›´æ–°è³‡æ–™åº«
    await prisma.summary.update({
      where: { id: params.id },
      data: {
        audioUrl,
        audioGeneratedAt: new Date(),
      },
    })

    console.log(`[Audio] èªéŸ³ç”ŸæˆæˆåŠŸ: ${audioUrl}`)

    return NextResponse.json({ audioUrl })
  } catch (error: any) {
    console.error('[Audio] ç”Ÿæˆå¤±æ•—:', error)

    // æ ¹æ“šéŒ¯èª¤é¡å‹å›å‚³ä¸åŒè¨Šæ¯
    if (error.code === 7) {
      // Google Cloud é…é¡ç”¨ç›¡
      return NextResponse.json(
        { error: 'å·²é”é…é¡ä¸Šé™ï¼Œè«‹æ˜æ—¥å†è©¦' },
        { status: 429 }
      )
    }

    return NextResponse.json(
      { error: 'èªéŸ³ç”Ÿæˆå¤±æ•—ï¼Œè«‹ç¨å¾Œé‡è©¦' },
      { status: 500 }
    )
  }
}
```

**Step 2: æ¸¬è©¦ APIï¼ˆæ‰‹å‹•ï¼‰**

åœ¨å®Œæˆ Google Cloud è¨­å®šå¾Œï¼Œå¯ä»¥ç”¨ curl æ¸¬è©¦ï¼š

```bash
# å–å¾—ä¸€å€‹ summaryIdï¼Œç„¶å¾Œæ¸¬è©¦
curl -X POST http://localhost:3000/api/summaries/{summaryId}/audio \
  -H "Cookie: next-auth.session-token=YOUR_TOKEN"
```

é æœŸï¼šå›å‚³ `{ "audioUrl": "https://storage.googleapis.com/..." }`

**Step 3: Commit**

```bash
git add app/api/summaries/[id]/audio/
git commit -m "feat(api): add audio generation endpoint"
```

---

## Phase 3: å‰ç«¯æ’­æ”¾å™¨çµ„ä»¶

### Task 6: å»ºç«‹ AudioPlayer çµ„ä»¶

**Files:**
- Create: `components/audio/AudioPlayer.tsx`

**Step 1: å»ºç«‹æ’­æ”¾å™¨çµ„ä»¶**

Create `components/audio/AudioPlayer.tsx`:

```typescript
'use client'

import { useState, useRef, useEffect } from 'react'
import { Play, Pause, Volume2, VolumeX, Loader2, RefreshCw } from 'lucide-react'

interface AudioPlayerProps {
  summaryId: string
}

type PlayerState = 'idle' | 'generating' | 'ready' | 'playing' | 'paused' | 'error'

export function AudioPlayer({ summaryId }: AudioPlayerProps) {
  const [state, setState] = useState<PlayerState>('idle')
  const [audioUrl, setAudioUrl] = useState<string | null>(null)
  const [currentTime, setCurrentTime] = useState(0)
  const [duration, setDuration] = useState(0)
  const [volume, setVolume] = useState(1)
  const [isMuted, setIsMuted] = useState(false)
  const [playbackRate, setPlaybackRate] = useState(1)
  const [error, setError] = useState<string | null>(null)

  const audioRef = useRef<HTMLAudioElement>(null)

  // ç”ŸæˆèªéŸ³
  const generateAudio = async () => {
    setState('generating')
    setError(null)

    try {
      const res = await fetch(`/api/summaries/${summaryId}/audio`, {
        method: 'POST',
      })

      if (!res.ok) {
        const data = await res.json()
        throw new Error(data.error || 'ç”Ÿæˆå¤±æ•—')
      }

      const { audioUrl: url } = await res.json()
      setAudioUrl(url)
      setState('ready')

      // è‡ªå‹•æ’­æ”¾
      setTimeout(() => {
        audioRef.current?.play()
      }, 100)
    } catch (err: any) {
      console.error('éŸ³è¨Šç”Ÿæˆå¤±æ•—:', err)
      setError(err.message)
      setState('error')
    }
  }

  // æ’­æ”¾/æš«åœ
  const togglePlay = () => {
    if (!audioRef.current) return

    if (state === 'playing') {
      audioRef.current.pause()
      setState('paused')
    } else {
      audioRef.current.play()
      setState('playing')
    }
  }

  // é¦–æ¬¡æ’­æ”¾
  const handleFirstPlay = () => {
    if (audioUrl) {
      togglePlay()
    } else {
      generateAudio()
    }
  }

  // é€²åº¦æ¢æ‹–æ›³
  const handleSeek = (e: React.ChangeEvent<HTMLInputElement>) => {
    const time = parseFloat(e.target.value)
    setCurrentTime(time)
    if (audioRef.current) {
      audioRef.current.currentTime = time
    }
  }

  // éŸ³é‡èª¿æ•´
  const handleVolumeChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    const vol = parseFloat(e.target.value)
    setVolume(vol)
    if (audioRef.current) {
      audioRef.current.volume = vol
    }
    if (vol > 0) setIsMuted(false)
  }

  // éœéŸ³åˆ‡æ›
  const toggleMute = () => {
    setIsMuted(!isMuted)
    if (audioRef.current) {
      audioRef.current.muted = !isMuted
    }
  }

  // æ’­æ”¾é€Ÿåº¦
  const handleRateChange = (rate: number) => {
    setPlaybackRate(rate)
    if (audioRef.current) {
      audioRef.current.playbackRate = rate
    }
  }

  // éŸ³è¨Šäº‹ä»¶ç›£è½
  useEffect(() => {
    const audio = audioRef.current
    if (!audio) return

    const handleTimeUpdate = () => setCurrentTime(audio.currentTime)
    const handleDurationChange = () => setDuration(audio.duration)
    const handleEnded = () => setState('paused')
    const handlePlay = () => setState('playing')
    const handlePause = () => setState('paused')

    audio.addEventListener('timeupdate', handleTimeUpdate)
    audio.addEventListener('durationchange', handleDurationChange)
    audio.addEventListener('ended', handleEnded)
    audio.addEventListener('play', handlePlay)
    audio.addEventListener('pause', handlePause)

    return () => {
      audio.removeEventListener('timeupdate', handleTimeUpdate)
      audio.removeEventListener('durationchange', handleDurationChange)
      audio.removeEventListener('ended', handleEnded)
      audio.removeEventListener('play', handlePlay)
      audio.removeEventListener('pause', handlePause)
    }
  }, [audioUrl])

  // æ ¼å¼åŒ–æ™‚é–“
  const formatTime = (seconds: number) => {
    if (!isFinite(seconds)) return '0:00'
    const mins = Math.floor(seconds / 60)
    const secs = Math.floor(seconds % 60)
    return `${mins}:${secs.toString().padStart(2, '0')}`
  }

  return (
    <div className="mb-8 p-6 bg-bg-secondary border border-white/10 rounded-lg">
      <div className="flex items-center gap-3 mb-4">
        <div className="text-lg font-semibold text-white font-rajdhani flex items-center gap-2">
          ğŸ§ èªéŸ³æ’­æ”¾
        </div>
      </div>

      {/* éŒ¯èª¤ç‹€æ…‹ */}
      {state === 'error' && (
        <div className="flex items-center justify-between bg-red-500/10 border border-red-500/30 rounded-lg p-4 mb-4">
          <p className="text-red-400 text-sm font-ibm">{error || 'èªéŸ³ç”Ÿæˆå¤±æ•—'}</p>
          <button
            onClick={generateAudio}
            className="flex items-center gap-2 px-3 py-1.5 bg-red-500/20 hover:bg-red-500/30 text-red-400 rounded transition font-ibm text-sm"
          >
            <RefreshCw className="w-4 h-4" />
            é‡è©¦
          </button>
        </div>
      )}

      {/* ç”Ÿæˆä¸­ç‹€æ…‹ */}
      {state === 'generating' && (
        <div className="flex items-center gap-3 text-brand-blue font-ibm">
          <Loader2 className="w-5 h-5 animate-spin" />
          <span>æ­£åœ¨ç”ŸæˆèªéŸ³...</span>
        </div>
      )}

      {/* æ’­æ”¾å™¨æ§åˆ¶ */}
      {(state === 'ready' || state === 'playing' || state === 'paused') && (
        <div className="space-y-4">
          {/* é€²åº¦æ¢ */}
          <div className="flex items-center gap-3">
            <span className="text-sm font-mono text-text-secondary min-w-[45px]">
              {formatTime(currentTime)}
            </span>
            <input
              type="range"
              min="0"
              max={duration || 0}
              value={currentTime}
              onChange={handleSeek}
              className="flex-1 h-2 bg-white/10 rounded-lg appearance-none cursor-pointer
                [&::-webkit-slider-thumb]:appearance-none [&::-webkit-slider-thumb]:w-4 [&::-webkit-slider-thumb]:h-4 
                [&::-webkit-slider-thumb]:rounded-full [&::-webkit-slider-thumb]:bg-brand-blue
                [&::-moz-range-thumb]:w-4 [&::-moz-range-thumb]:h-4 
                [&::-moz-range-thumb]:rounded-full [&::-moz-range-thumb]:bg-brand-blue [&::-moz-range-thumb]:border-0"
            />
            <span className="text-sm font-mono text-text-secondary min-w-[45px]">
              {formatTime(duration)}
            </span>
          </div>

          {/* æ§åˆ¶æŒ‰éˆ• */}
          <div className="flex items-center gap-4">
            {/* æ’­æ”¾/æš«åœ */}
            <button
              onClick={togglePlay}
              className="p-3 bg-brand-blue hover:bg-blue-600 text-white rounded-full transition"
            >
              {state === 'playing' ? (
                <Pause className="w-5 h-5" />
              ) : (
                <Play className="w-5 h-5" />
              )}
            </button>

            {/* éŸ³é‡æ§åˆ¶ */}
            <div className="flex items-center gap-2">
              <button
                onClick={toggleMute}
                className="p-2 hover:bg-white/5 rounded transition"
              >
                {isMuted || volume === 0 ? (
                  <VolumeX className="w-5 h-5 text-text-secondary" />
                ) : (
                  <Volume2 className="w-5 h-5 text-text-secondary" />
                )}
              </button>
              <input
                type="range"
                min="0"
                max="1"
                step="0.01"
                value={volume}
                onChange={handleVolumeChange}
                className="w-20 h-2 bg-white/10 rounded-lg appearance-none cursor-pointer
                  [&::-webkit-slider-thumb]:appearance-none [&::-webkit-slider-thumb]:w-3 [&::-webkit-slider-thumb]:h-3 
                  [&::-webkit-slider-thumb]:rounded-full [&::-webkit-slider-thumb]:bg-text-secondary
                  [&::-moz-range-thumb]:w-3 [&::-moz-range-thumb]:h-3 
                  [&::-moz-range-thumb]:rounded-full [&::-moz-range-thumb]:bg-text-secondary [&::-moz-range-thumb]:border-0"
              />
            </div>

            {/* æ’­æ”¾é€Ÿåº¦ */}
            <div className="flex items-center gap-1">
              {[1, 1.25, 1.5, 2].map((rate) => (
                <button
                  key={rate}
                  onClick={() => handleRateChange(rate)}
                  className={`px-3 py-1 text-sm rounded transition font-ibm ${
                    playbackRate === rate
                      ? 'bg-brand-blue text-white'
                      : 'bg-white/5 text-text-secondary hover:bg-white/10'
                  }`}
                >
                  {rate}x
                </button>
              ))}
            </div>
          </div>
        </div>
      )}

      {/* åˆå§‹ç‹€æ…‹ï¼šæ’­æ”¾æŒ‰éˆ• */}
      {state === 'idle' && (
        <button
          onClick={handleFirstPlay}
          className="flex items-center gap-2 px-4 py-2 bg-brand-blue hover:bg-blue-600 text-white rounded-lg transition font-ibm"
        >
          <Play className="w-5 h-5" />
          æ’­æ”¾èªéŸ³
        </button>
      )}

      {/* éš±è—çš„ audio å…ƒç´  */}
      {audioUrl && (
        <audio ref={audioRef} src={audioUrl} preload="metadata" />
      )}
    </div>
  )
}
```

**Step 2: Commit**

```bash
git add components/audio/
git commit -m "feat(ui): add AudioPlayer component"
```

---

### Task 7: æ•´åˆæ’­æ”¾å™¨åˆ°æ‘˜è¦è©³ç´°é 

**Files:**
- Modify: `app/(dashboard)/summaries/[id]/page.tsx`

**Step 1: åŒ¯å…¥ AudioPlayer çµ„ä»¶**

åœ¨æª”æ¡ˆé ‚éƒ¨çš„ import å€å¡Šæ–°å¢ï¼š

```typescript
import { AudioPlayer } from '@/components/audio/AudioPlayer'
```

**Step 2: åœ¨é é¢ä¸­æ’å…¥æ’­æ”¾å™¨**

æ‰¾åˆ°é€™æ®µç¨‹å¼ç¢¼ï¼ˆå¤§ç´„åœ¨ line 183ï¼‰ï¼š

```typescript
        </div>
      </div>

      {/* ä¸»é¡Œ */}
      <div className="mb-8 p-6 bg-bg-secondary border border-white/10 rounded-lg">
```

åœ¨ `{/* ä¸»é¡Œ */}` ä¹‹å‰æ’å…¥ï¼š

```typescript
        </div>
      </div>

      {/* èªéŸ³æ’­æ”¾å™¨ */}
      <AudioPlayer summaryId={summary.id} />

      {/* ä¸»é¡Œ */}
      <div className="mb-8 p-6 bg-bg-secondary border border-white/10 rounded-lg">
```

**Step 3: Commit**

```bash
git add app/(dashboard)/summaries/[id]/page.tsx
git commit -m "feat(ui): integrate AudioPlayer into summary detail page"
```

---

## Phase 4: æ¸¬è©¦èˆ‡é™¤éŒ¯

### Task 8: æ‰‹å‹•æ¸¬è©¦å®Œæ•´æµç¨‹

**Step 1: è¨­å®š Google Cloudï¼ˆæ‰‹å‹•æ“ä½œï¼‰**

1. å‰å¾€ [Google Cloud Console](https://console.cloud.google.com)
2. å•Ÿç”¨ Cloud Text-to-Speech API
3. å•Ÿç”¨ Cloud Storage API
4. å»ºç«‹ GCS Bucketï¼š`tube-mind-audio-dev`
5. å»ºç«‹æœå‹™å¸³è™Ÿï¼Œæˆäºˆæ¬Šé™ï¼š
   - Cloud Storage Admin
   - Cloud Text-to-Speech User
6. ä¸‹è¼‰æœå‹™å¸³è™Ÿ JSON é‡‘é‘°åˆ°å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼Œå‘½åç‚º `service-account-key.json`
7. ç¢ºèª `.env.local` ç’°å¢ƒè®Šæ•¸å·²è¨­å®š

**Step 2: å•Ÿå‹•é–‹ç™¼ä¼ºæœå™¨**

```bash
npm run dev
```

**Step 3: æ¸¬è©¦æµç¨‹**

1. ç™»å…¥æ‡‰ç”¨ç¨‹å¼
2. é€²å…¥ä»»ä¸€å·²å®Œæˆçš„æ‘˜è¦è©³ç´°é 
3. æ‡‰è©²çœ‹åˆ°ã€ŒğŸ§ èªéŸ³æ’­æ”¾ã€å€å¡Š
4. é»æ“Šã€Œæ’­æ”¾èªéŸ³ã€æŒ‰éˆ•
5. è§€å¯Ÿç‹€æ…‹ï¼š
   - æ‡‰é¡¯ç¤ºã€Œæ­£åœ¨ç”ŸæˆèªéŸ³...ã€
   - 2-5 ç§’å¾Œè‡ªå‹•é–‹å§‹æ’­æ”¾
   - æ’­æ”¾å™¨æ§åˆ¶æ‡‰è©²æ­£å¸¸é‹ä½œ

**Step 4: æ¸¬è©¦å¿«å–**

1. é‡æ–°æ•´ç†é é¢
2. å†æ¬¡é»æ“Šæ’­æ”¾
3. æ‡‰è©²ç«‹å³æ’­æ”¾ï¼Œä¸éœ€ç­‰å¾…ç”Ÿæˆ

**Step 5: æ¸¬è©¦éŒ¯èª¤è™•ç†**

1. æš«æ™‚ç§»é™¤ `GOOGLE_APPLICATION_CREDENTIALS` ç’°å¢ƒè®Šæ•¸
2. é‡æ–°å•Ÿå‹• dev server
3. å˜—è©¦æ’­æ”¾
4. æ‡‰é¡¯ç¤ºéŒ¯èª¤è¨Šæ¯å’Œé‡è©¦æŒ‰éˆ•

**Step 6: æª¢æŸ¥ GCS**

1. å‰å¾€ Google Cloud Console > Cloud Storage
2. æŸ¥çœ‹ bucket ä¸­æ˜¯å¦æœ‰ `audio/{summaryId}.mp3` æª”æ¡ˆ
3. ç¢ºèªæª”æ¡ˆå¯å…¬é–‹å­˜å–

**Step 7: è¨˜éŒ„æ¸¬è©¦çµæœ**

å»ºç«‹ `docs/testing/audio-playback-manual-test.md` è¨˜éŒ„æ¸¬è©¦çµæœã€‚

---

### Task 9: æª¢æŸ¥è³‡æ–™åº«æ›´æ–°

**Step 1: æŸ¥è©¢è³‡æ–™åº«**

```bash
npx prisma studio
```

**Step 2: æª¢æŸ¥ Summary è¡¨**

1. æ‰¾åˆ°å‰›æ‰æ¸¬è©¦çš„æ‘˜è¦
2. ç¢ºèª `audioUrl` æ¬„ä½å·²å¡«å…¥ GCS URL
3. ç¢ºèª `audioGeneratedAt` æ¬„ä½å·²è¨­å®šæ™‚é–“

**Step 3: è¨˜éŒ„**

å¦‚æœä¸€åˆ‡æ­£å¸¸ï¼Œåœ¨æ¸¬è©¦æ–‡ä»¶ä¸­è¨˜éŒ„ã€Œâœ… è³‡æ–™åº«æ›´æ–°æ­£å¸¸ã€ã€‚

---

## Phase 5: å„ªåŒ–èˆ‡æ–‡ä»¶

### Task 10: æ–°å¢ Loading ç‹€æ…‹å„ªåŒ–

**Files:**
- Modify: `components/audio/AudioPlayer.tsx`

**Step 1: æ–°å¢é€²åº¦æ–‡å­—**

åœ¨ `state === 'generating'` çš„å€å¡Šä¸­ï¼Œæ”¹é€² UIï¼š

```typescript
{state === 'generating' && (
  <div className="flex flex-col gap-2">
    <div className="flex items-center gap-3 text-brand-blue font-ibm">
      <Loader2 className="w-5 h-5 animate-spin" />
      <span>æ­£åœ¨ç”ŸæˆèªéŸ³...</span>
    </div>
    <p className="text-sm text-text-secondary font-ibm">
      é¦–æ¬¡ç”Ÿæˆéœ€è¦ 2-5 ç§’ï¼Œä¹‹å¾Œæœƒè‡ªå‹•å¿«å–
    </p>
  </div>
)}
```

**Step 2: Commit**

```bash
git add components/audio/AudioPlayer.tsx
git commit -m "feat(ui): improve loading state UX"
```

---

### Task 11: æ›´æ–°å°ˆæ¡ˆæ–‡ä»¶

**Files:**
- Modify: `README.md`
- Create: `docs/features/audio-playback.md`

**Step 1: æ–°å¢åŠŸèƒ½èªªæ˜åˆ° README**

åœ¨ `README.md` çš„ Features å€å¡Šæ–°å¢ï¼š

```markdown
### ğŸ§ èªéŸ³æ’­å ±

- AI èªéŸ³æœ—è®€æ‘˜è¦å…§å®¹
- æ”¯æ´æ’­æ”¾é€Ÿåº¦èª¿æ•´ï¼ˆ1x - 2xï¼‰
- æ™ºèƒ½å¿«å–ï¼Œé¦–æ¬¡ç”Ÿæˆå¾Œç«‹å³æ’­æ”¾
- ä½¿ç”¨ Google Cloud TTSï¼Œé«˜å“è³ªç¹é«”ä¸­æ–‡èªéŸ³
```

**Step 2: å»ºç«‹åŠŸèƒ½æ–‡ä»¶**

Create `docs/features/audio-playback.md`:

```markdown
# èªéŸ³æ’­å ±åŠŸèƒ½

## æ¦‚è¿°

ä½¿ç”¨è€…å¯ä»¥åœ¨æ‘˜è¦è©³ç´°é é¢æ’­æ”¾ AI èªéŸ³ç‰ˆæœ¬çš„æ‘˜è¦å…§å®¹ã€‚

## æŠ€è¡“æ¶æ§‹

- **TTS**: Google Cloud Text-to-Speech (zh-TW)
- **å„²å­˜**: Google Cloud Storage
- **å‰ç«¯**: React + HTML5 Audio API

## ä½¿ç”¨æ–¹å¼

1. é€²å…¥ä»»ä¸€å®Œæˆçš„æ‘˜è¦é é¢
2. é»æ“Šã€Œæ’­æ”¾èªéŸ³ã€æŒ‰éˆ•
3. é¦–æ¬¡æ’­æ”¾æœƒç”ŸæˆèªéŸ³ï¼ˆ2-5 ç§’ï¼‰
4. å¾ŒçºŒæ’­æ”¾ç«‹å³è¼‰å…¥å¿«å–

## æ’­æ”¾å™¨åŠŸèƒ½

- â–¶ï¸ æ’­æ”¾/æš«åœ
- ğŸšï¸ é€²åº¦æ¢æ‹–æ›³
- ğŸ”Š éŸ³é‡æ§åˆ¶
- âš¡ æ’­æ”¾é€Ÿåº¦ï¼ˆ1x, 1.25x, 1.5x, 2xï¼‰

## ç’°å¢ƒè¨­å®š

éœ€è¦è¨­å®šä»¥ä¸‹ç’°å¢ƒè®Šæ•¸ï¼š

```env
GOOGLE_APPLICATION_CREDENTIALS=./service-account-key.json
GCS_BUCKET_NAME=tube-mind-audio-prod
```

## Google Cloud è¨­å®š

1. å•Ÿç”¨ Cloud Text-to-Speech API
2. å•Ÿç”¨ Cloud Storage API
3. å»ºç«‹ GCS Bucket
4. å»ºç«‹æœå‹™å¸³è™Ÿä¸¦ä¸‹è¼‰é‡‘é‘°

è©³è¦‹ï¼š`docs/plans/2026-01-21-audio-playback-design.md`
```

**Step 3: Commit**

```bash
git add README.md docs/features/
git commit -m "docs: add audio playback feature documentation"
```

---

## Phase 6: æœ€çµ‚æª¢æŸ¥èˆ‡åˆä½µ

### Task 12: ç¨‹å¼ç¢¼æª¢æŸ¥

**Step 1: TypeScript å‹åˆ¥æª¢æŸ¥**

```bash
npx tsc --noEmit
```

é æœŸï¼šç„¡éŒ¯èª¤

**Step 2: Linting**

```bash
npm run lint
```

é æœŸï¼šç„¡éŒ¯èª¤æˆ–è­¦å‘Šï¼ˆæˆ–åªæœ‰åˆç†çš„è­¦å‘Šï¼‰

**Step 3: æ ¼å¼åŒ–**

```bash
npx prettier --write "components/audio/**" "app/api/summaries/**/audio/**" "lib/audio/**"
```

**Step 4: Commit**

å¦‚æœ‰ä¿®æ”¹ï¼š

```bash
git add .
git commit -m "style: format code with prettier"
```

---

### Task 13: å»ºç«‹ Pull Request

**Step 1: æ¨é€åˆ†æ”¯**

```bash
git push -u origin feature/audio-playback
```

**Step 2: æª¢è¦–è®Šæ›´**

```bash
git log main..HEAD --oneline
```

ç¢ºèªæ‰€æœ‰ commit éƒ½åˆç†ã€‚

**Step 3: å»ºç«‹ PRï¼ˆæ‰‹å‹•ï¼‰**

1. å‰å¾€ GitHub 
2. å»ºç«‹ Pull Request
3. æ¨™é¡Œï¼š`feat: æ–°å¢èªéŸ³æ’­å ±åŠŸèƒ½`
4. å…§å®¹ï¼š

```markdown
## åŠŸèƒ½

æ–°å¢èªéŸ³æ’­å ±åŠŸèƒ½ï¼Œä½¿ç”¨è€…å¯åœ¨æ‘˜è¦è©³ç´°é é¢æ’­æ”¾ AI èªéŸ³ç‰ˆæ‘˜è¦ã€‚

## è®Šæ›´

- âœ… è³‡æ–™åº«æ–°å¢ `audioUrl` å’Œ `audioGeneratedAt` æ¬„ä½
- âœ… æ•´åˆ Google Cloud TTS å’Œ GCS
- âœ… å¯¦ä½œéŸ³è¨Šç”Ÿæˆ API ç«¯é»
- âœ… å»ºç«‹ç¾ä»£åŒ–æ’­æ”¾å™¨ UIï¼ˆæ”¯æ´å€é€Ÿã€é€²åº¦æ¢ã€éŸ³é‡ï¼‰
- âœ… é¦–æ¬¡ç”Ÿæˆå¿«å–æ©Ÿåˆ¶

## æ¸¬è©¦

- [x] æ‰‹å‹•æ¸¬è©¦ç”Ÿæˆæµç¨‹
- [x] æ¸¬è©¦å¿«å–æ©Ÿåˆ¶
- [x] æ¸¬è©¦éŒ¯èª¤è™•ç†
- [x] æª¢æŸ¥è³‡æ–™åº«æ›´æ–°
- [x] TypeScript å‹åˆ¥æª¢æŸ¥é€šé
- [x] Linting é€šé

## æˆªåœ–

ï¼ˆå¯é¸ï¼šåŠ å…¥æ’­æ”¾å™¨æˆªåœ–ï¼‰

## ç›¸é—œæ–‡ä»¶

- è¨­è¨ˆæ–‡ä»¶ï¼š`docs/plans/2026-01-21-audio-playback-design.md`
- åŠŸèƒ½æ–‡ä»¶ï¼š`docs/features/audio-playback.md`
```

---

## å®Œæˆæª¢æŸ¥æ¸…å–®

åŸ·è¡Œå®Œæ‰€æœ‰ä»»å‹™å¾Œï¼Œç¢ºèªä»¥ä¸‹é …ç›®ï¼š

- [ ] Prisma schema å·²æ›´æ–°ä¸¦åŸ·è¡Œ migration
- [ ] Google Cloud å¥—ä»¶å·²å®‰è£
- [ ] ç’°å¢ƒè®Šæ•¸å·²è¨­å®šï¼ˆ`.env.local` å’Œ `.env.example`ï¼‰
- [ ] TTS å’Œ GCS å·¥å…·å‡½å¼å·²å»ºç«‹
- [ ] API ç«¯é»å·²å¯¦ä½œä¸¦æ¸¬è©¦
- [ ] AudioPlayer çµ„ä»¶å·²å»ºç«‹
- [ ] æ’­æ”¾å™¨å·²æ•´åˆåˆ°æ‘˜è¦é é¢
- [ ] æ‰‹å‹•æ¸¬è©¦å®Œæ•´æµç¨‹é€šé
- [ ] è³‡æ–™åº«æ›´æ–°æ­£å¸¸
- [ ] UI å„ªåŒ–å®Œæˆ
- [ ] æ–‡ä»¶å·²æ›´æ–°
- [ ] ç¨‹å¼ç¢¼æª¢æŸ¥é€šé
- [ ] Pull Request å·²å»ºç«‹

---

## æ³¨æ„äº‹é …

1. **Google Cloud è¨­å®š**: åœ¨é–‹å§‹å¯¦ä½œå‰ï¼Œå‹™å¿…å®Œæˆ Google Cloud çš„è¨­å®šï¼ˆTask 8 Step 1ï¼‰
2. **ç’°å¢ƒè®Šæ•¸**: ç¢ºä¿ `service-account-key.json` ä¸è¢« commit åˆ° git
3. **æ¸¬è©¦**: æ¯å€‹ Task å®Œæˆå¾Œéƒ½è¦æ¸¬è©¦ï¼Œä¸è¦ç´¯ç©å•é¡Œ
4. **Commit é »ç‡**: æ¯å€‹ Task è‡³å°‘ä¸€å€‹ commitï¼Œä¿æŒå°æ­¥æäº¤
5. **éŒ¯èª¤è™•ç†**: é‡åˆ°å•é¡Œå…ˆæŸ¥çœ‹ console logï¼ŒGoogle Cloud éŒ¯èª¤é€šå¸¸æœ‰æ˜ç¢ºçš„è¨Šæ¯

---

**è¨ˆç•«å»ºç«‹æ—¥æœŸ**: 2026-01-21  
**é ä¼°å®Œæˆæ™‚é–“**: 2-3 å°æ™‚ï¼ˆä¸å« Google Cloud æ‰‹å‹•è¨­å®šæ™‚é–“ï¼‰
